{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 6 - Prediction & Causal Inference\n",
    "\n",
    "Last week, we covered the classification of text, such as classifying Reddit posts by thread topic. Classification often uses a representative sample of the text that we want to make inferences about, such as if we can human-code only a random sample of texts and then use ML to classify the rest.\n",
    "\n",
    "This week, we talk about two different types of inferences to out-of-sample populations. _Text as Data_ defines _prediction_ by the question: \"What value of the outcome do we expect for a unit or units out of a distinct population of units?\" Often this is prediction for the future. We don't expect the weather today to be identical to the weather tomorrow, but it should contain some useful information. They define _causal inference_ by the question: \"How do outcomes differ if we intervene in the world?\" Causality is a deeply contested notion in science and philosophy, but it usually involves an \"if,\" a different between two counterfactual worlds, one where an event occurs and one where it doesn't.\n",
    "\n",
    "For this notebook we will be using the following packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Special module written for this class\n",
    "#This provides access to data and to helper functions from previous weeks\n",
    "#Make sure you update it before starting this notebook\n",
    "import lucem_illud #pip install -U git+git://github.com/UChicago-Computational-Content-Analysis/lucem_illud.git\n",
    "\n",
    "#All these packages need to be installed from pip\n",
    "import requests #For getting files\n",
    "import zipfile #For managing zips\n",
    "import numpy as np #For arrays\n",
    "import scipy as sp #For some stats\n",
    "import pandas as pd #Gives us DataFrames\n",
    "import numpy as np #Math and matrices\n",
    "import matplotlib.pyplot as plt #For graphics\n",
    "\n",
    "# statsmodels is a popular Python statistics package\n",
    "import statsmodels.api as sm\n",
    "# Let's also import its graphics module\n",
    "import statsmodels.graphics.api as smg\n",
    "# And the mediation module\n",
    "from statsmodels.stats.mediation import Mediation\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "#This 'magic' command makes the plots work better\n",
    "#in the notebook, don't use it outside of a notebook.\n",
    "#Also you can ignore the warning\n",
    "%matplotlib inline\n",
    "\n",
    "import os #For looking through files\n",
    "import os.path #For managing file paths\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction\n",
    "We can make predictions about a range of different populations of texts. We can use texts in English to predict their translated version in French. We can use newspaper articles from 2012 to 2022 to predict 2023 newspaper articles (e.g., a [time series](https://en.wikipedia.org/wiki/Time_series)). Instead of forecasting, we can \"nowcast\" by using real-time social information such as Tweets to predict when an important event is happening, such as a riot.\n",
    "\n",
    "If we don't have any information about how the new population will vary from the population we learned from, then prediction is implemented in the same way as in-sample inference. For example, if you have a categorization of 2022 emails as spam or not, you could predict whether 2023 emails are spam the same way you predicted 2022 emails. On the other hand, if you have new information, such as a trend beginning in December 2022 for spam emails to have \"Urgent:\" in the subject line, your 2023 prediction may differ by putting more weight on that indicator relative to others.\n",
    "\n",
    "We currently don't have code for this, because it's so similar to the classification last week, but we encourage you to think more about this if you're interested in predicting the future of your corpus!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text in causal inference\n",
    "\n",
    "In causal inference, we are interested in the effect of a _treatment_ on an _outcome_. There are five sorts of variables that could be directly involved in our causal model, and any of them could be a text variable. This figure from [Keith et al. 2020](https://aclanthology.org/2020.acl-main.474.pdf) concisely shows the five positions for variables in acyclic (i.e., no arrows flow back into themselves) causal inference: treatment, mediator, outcome, confounder, and collider.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/UChicago-Computational-Content-Analysis/Homework-Notebooks/main/week-6/img/causal_diagram.png\" alt=\"https://raw.githubusercontent.com/UChicago-Computational-Content-Analysis/Homework-Notebooks/main/week-6/img/causal_diagram.png\" style=\"width:500px\">\n",
    "\n",
    "\"Text as treatment\" means the effect of text on other variables. For example, how does the news coverage of a politician affect their election chance? How does the sentiment of a Reddit post affect its upvotes?\n",
    "\n",
    "Whether we're interested in text as treatment, mediator, outcome, or confounder, we have at our disposal the same causal inference strategies used with other forms of data, such as matching, difference in difference, regression discontinuity, and instrumental variable. Each of these methods usually gives you a more precise identification of the causal effect than a plain regression. For example, one of the readings for this week, [Saha 2019](https://doi.org/10.1145/3292522.3326032), uses propensity score matching, which is a straightforward method that works on most datasets but has relatively weak identification. Some scholars such as Gary King advocate for an improved method, [coarsened exact matching](https://www.youtube.com/watch?v=tvMyjDi4dyg). However, for this assignment, we do not go into these methods. We only use simple regressions. There are several courses at UChicago that introduce these methods, as well as online textbooks like Scott Cunningham's [Causal Inference: The Mixtape](https://mixtape.scunning.com/), which is geared towards economists.\n",
    "\n",
    "You can do causal inference on any sort of text data as long as you have a plausible _identification_ strategy, meaning an argument that you can correctly identify a causal effect if one exists using your data and analysis. For example, if you have a data from a randomized controlled trial (RCT) where you intervene randomly with some treatment, you can identify a causal effect with relative ease."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text as treatment and outcome\n",
    "\n",
    "To show text as treatment and outcome, we will analyze a dataset of internet arguments. We have 8,8895 pairs of comments, where one person makes a statement and the other responds. Our research question is thus: _How does the text of the first commenter affect the text of the respondent?_\n",
    "\n",
    "The data comes from the [Internet Argument Corpus](https://nlds.soe.ucsc.edu/iac). Let's load the data and take a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded file: http://nldslab.soe.ucsc.edu/iac/iac_v1.1.zip\n"
     ]
    }
   ],
   "source": [
    "url = 'http://nldslab.soe.ucsc.edu/iac/iac_v1.1.zip'\n",
    "\n",
    "req = requests.get(url)\n",
    "\n",
    "filename = url.split('/')[-1]\n",
    "with open(filename,'wb') as output_file:\n",
    "    output_file.write(req.content)\n",
    "print('Downloaded file: ' + url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>discussion_id_x</th>\n",
       "      <th>agree-disagree</th>\n",
       "      <th>agreement</th>\n",
       "      <th>agreement_unsure</th>\n",
       "      <th>attack</th>\n",
       "      <th>attack_unsure</th>\n",
       "      <th>defeater-undercutter</th>\n",
       "      <th>defeater-undercutter_unsure</th>\n",
       "      <th>fact-feeling</th>\n",
       "      <th>fact-feeling_unsure</th>\n",
       "      <th>negotiate-attack</th>\n",
       "      <th>negotiate-attack_unsure</th>\n",
       "      <th>nicenasty</th>\n",
       "      <th>nicenasty_unsure</th>\n",
       "      <th>personal-audience</th>\n",
       "      <th>personal-audience_unsure</th>\n",
       "      <th>questioning-asserting</th>\n",
       "      <th>questioning-asserting_unsure</th>\n",
       "      <th>sarcasm</th>\n",
       "      <th>sarcasm_unsure</th>\n",
       "      <th>discussion_id_y</th>\n",
       "      <th>response_post_id</th>\n",
       "      <th>quote_post_id</th>\n",
       "      <th>term</th>\n",
       "      <th>task1 num annot</th>\n",
       "      <th>task2 num annot</th>\n",
       "      <th>task2 num disagree</th>\n",
       "      <th>quote</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(731, 1)</td>\n",
       "      <td>6032</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>-1.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>-2.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>-4.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>6032</td>\n",
       "      <td>149609</td>\n",
       "      <td>149552.0</td>\n",
       "      <td>None</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>I remember looking at the classic evolutionary...</td>\n",
       "      <td>Why do you find it necessary to fit observatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(660, 3)</td>\n",
       "      <td>10217</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10217</td>\n",
       "      <td>277697</td>\n",
       "      <td>277459.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>So they (pro-life peeps) say abortion is murde...</td>\n",
       "      <td>Yes, you are missing something. How come age d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(114, 5)</td>\n",
       "      <td>3462</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3462</td>\n",
       "      <td>76012</td>\n",
       "      <td>75976.0</td>\n",
       "      <td>No terms in first 10</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>'If the solar system was brought about by an a...</td>\n",
       "      <td>C.S.Lewis believes things on faith, yet we are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(43, 3)</td>\n",
       "      <td>9930</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>-0.833333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9930</td>\n",
       "      <td>264824</td>\n",
       "      <td>264697.0</td>\n",
       "      <td>well</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>...to ToE because it means genetic evolution i...</td>\n",
       "      <td>Well, it might help if you could propose a mec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(1314, 0)</td>\n",
       "      <td>5352</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>-1.666667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>-1.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>-0.833333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>-3.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>5352</td>\n",
       "      <td>128326</td>\n",
       "      <td>128325.0</td>\n",
       "      <td>you</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>Sir Issac Newton was an idiot and you are a ge...</td>\n",
       "      <td>You really think so? Im flattered, but I think...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>(580, 4)</td>\n",
       "      <td>821</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>821</td>\n",
       "      <td>67788</td>\n",
       "      <td>67785.0</td>\n",
       "      <td>oh</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Why do some of you guys insist on being rabid ...</td>\n",
       "      <td>oh because for the past decade or so they have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>(694, 4)</td>\n",
       "      <td>9258</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>-1.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>-1.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>-1.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>9258</td>\n",
       "      <td>241951</td>\n",
       "      <td>241848.0</td>\n",
       "      <td>but</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>But I see two people involved here. Whether th...</td>\n",
       "      <td>But the embryo is a mere clump of flesh inside...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>(916, 6)</td>\n",
       "      <td>10301</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-4.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>10301</td>\n",
       "      <td>281530</td>\n",
       "      <td>281509.0</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>I disagree with you because the logic you have...</td>\n",
       "      <td>**\\n Sez u. Your problem being that when you a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>(1348, 1)</td>\n",
       "      <td>6032</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.600000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>6032</td>\n",
       "      <td>149609</td>\n",
       "      <td>149552.0</td>\n",
       "      <td>No terms in first 10</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>What I don't understand is why YEC's want to L...</td>\n",
       "      <td>That's what faith does. It limits your options.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>(484, 0)</td>\n",
       "      <td>3426</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>-2.833333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>3426</td>\n",
       "      <td>71284</td>\n",
       "      <td>71253.0</td>\n",
       "      <td>No terms in first 10</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>Perhaps also you might want to consider where ...</td>\n",
       "      <td>On the contrary... These individuals (or indiv...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8895 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             key  discussion_id_x  agree-disagree  agreement  \\\n",
       "0       (731, 1)             6032        0.333333  -1.333333   \n",
       "1       (660, 3)            10217        0.600000   0.285714   \n",
       "2       (114, 5)             3462        0.600000  -1.500000   \n",
       "3        (43, 3)             9930        0.166667  -0.833333   \n",
       "4      (1314, 0)             5352        0.142857  -1.666667   \n",
       "...          ...              ...             ...        ...   \n",
       "9995    (580, 4)              821        0.800000  -2.000000   \n",
       "9997    (694, 4)             9258        0.000000  -3.200000   \n",
       "9998    (916, 6)            10301        0.000000  -3.000000   \n",
       "9999   (1348, 1)             6032        0.857143   0.800000   \n",
       "10000   (484, 0)             3426        0.142857  -2.833333   \n",
       "\n",
       "       agreement_unsure    attack  attack_unsure  defeater-undercutter  \\\n",
       "0              0.333333  0.333333       0.000000              0.500000   \n",
       "1              0.000000  0.714286       0.000000             -2.500000   \n",
       "2              0.000000  1.333333       0.000000              1.000000   \n",
       "3              0.333333  1.500000       0.000000              0.400000   \n",
       "4              0.166667  0.000000       0.166667             -1.166667   \n",
       "...                 ...       ...            ...                   ...   \n",
       "9995           0.166667 -0.500000       0.166667              1.000000   \n",
       "9997           0.200000  0.200000       0.200000             -1.800000   \n",
       "9998           0.000000 -2.400000       0.000000             -2.400000   \n",
       "9999           0.600000  0.600000       0.200000              3.000000   \n",
       "10000          0.166667  0.833333       0.166667             -1.000000   \n",
       "\n",
       "       defeater-undercutter_unsure  fact-feeling  fact-feeling_unsure  \\\n",
       "0                         0.000000      0.333333             0.333333   \n",
       "1                         0.000000      1.000000             0.000000   \n",
       "2                         0.000000      1.500000             0.000000   \n",
       "3                         0.000000      1.500000             0.166667   \n",
       "4                         0.166667     -0.833333             0.333333   \n",
       "...                            ...           ...                  ...   \n",
       "9995                      0.000000      1.333333             0.166667   \n",
       "9997                      0.000000      1.600000             0.400000   \n",
       "9998                      0.000000     -2.400000             0.000000   \n",
       "9999                      0.000000     -0.600000             0.400000   \n",
       "10000                     0.000000      0.833333             0.333333   \n",
       "\n",
       "       negotiate-attack  negotiate-attack_unsure  nicenasty  nicenasty_unsure  \\\n",
       "0              3.000000                 0.250000   0.666667          0.166667   \n",
       "1             -2.000000                 0.000000   1.142857          0.000000   \n",
       "2             -1.500000                 0.000000   2.166667          0.000000   \n",
       "3             -2.000000                 0.000000   1.666667          0.000000   \n",
       "4              0.833333                 0.333333   0.166667          0.166667   \n",
       "...                 ...                      ...        ...               ...   \n",
       "9995          -1.000000                 0.000000   0.500000          0.166667   \n",
       "9997          -1.200000                 0.200000   0.600000          0.200000   \n",
       "9998           2.800000                 0.000000  -2.400000          0.000000   \n",
       "9999          -3.000000                 0.000000   0.600000          0.200000   \n",
       "10000         -2.000000                 0.000000   1.500000          0.333333   \n",
       "\n",
       "       personal-audience  personal-audience_unsure  questioning-asserting  \\\n",
       "0              -2.250000                  0.250000              -4.250000   \n",
       "1              -1.500000                  0.000000               0.500000   \n",
       "2              -4.000000                  0.000000              -1.500000   \n",
       "3              -2.800000                  0.000000               0.000000   \n",
       "4              -3.333333                  0.166667              -0.166667   \n",
       "...                  ...                       ...                    ...   \n",
       "9995            0.000000                  0.000000               0.000000   \n",
       "9997           -1.600000                  0.000000               1.800000   \n",
       "9998           -4.200000                  0.000000               1.800000   \n",
       "9999            3.000000                  0.000000               3.000000   \n",
       "10000           2.333333                  0.000000               0.833333   \n",
       "\n",
       "       questioning-asserting_unsure   sarcasm  sarcasm_unsure  \\\n",
       "0                          0.000000  0.200000        0.166667   \n",
       "1                          0.000000  0.142857        0.000000   \n",
       "2                          0.000000  0.000000        0.000000   \n",
       "3                          0.000000  0.000000        0.000000   \n",
       "4                          0.166667  0.600000        0.166667   \n",
       "...                             ...       ...             ...   \n",
       "9995                       0.000000  0.200000        0.166667   \n",
       "9997                       0.000000  0.000000        0.200000   \n",
       "9998                       0.000000  0.000000        0.200000   \n",
       "9999                       0.000000  0.000000        0.200000   \n",
       "10000                      0.000000  0.000000        0.166667   \n",
       "\n",
       "       discussion_id_y  response_post_id  quote_post_id                  term  \\\n",
       "0                 6032            149609       149552.0                  None   \n",
       "1                10217            277697       277459.0                   yes   \n",
       "2                 3462             76012        75976.0  No terms in first 10   \n",
       "3                 9930            264824       264697.0                  well   \n",
       "4                 5352            128326       128325.0                   you   \n",
       "...                ...               ...            ...                   ...   \n",
       "9995               821             67788        67785.0                    oh   \n",
       "9997              9258            241951       241848.0                   but   \n",
       "9998             10301            281530       281509.0                  None   \n",
       "9999              6032            149609       149552.0  No terms in first 10   \n",
       "10000             3426             71284        71253.0  No terms in first 10   \n",
       "\n",
       "       task1 num annot  task2 num annot  task2 num disagree  \\\n",
       "0                    6                6                   4   \n",
       "1                    7                5                   2   \n",
       "2                    6                5                   2   \n",
       "3                    6                6                   5   \n",
       "4                    6                7                   6   \n",
       "...                ...              ...                 ...   \n",
       "9995                 6                5                   1   \n",
       "9997                 5                5                   5   \n",
       "9998                 5                5                   5   \n",
       "9999                 5                7                   1   \n",
       "10000                6                7                   6   \n",
       "\n",
       "                                                   quote  \\\n",
       "0      I remember looking at the classic evolutionary...   \n",
       "1      So they (pro-life peeps) say abortion is murde...   \n",
       "2      'If the solar system was brought about by an a...   \n",
       "3      ...to ToE because it means genetic evolution i...   \n",
       "4      Sir Issac Newton was an idiot and you are a ge...   \n",
       "...                                                  ...   \n",
       "9995   Why do some of you guys insist on being rabid ...   \n",
       "9997   But I see two people involved here. Whether th...   \n",
       "9998   I disagree with you because the logic you have...   \n",
       "9999   What I don't understand is why YEC's want to L...   \n",
       "10000  Perhaps also you might want to consider where ...   \n",
       "\n",
       "                                                response  \n",
       "0      Why do you find it necessary to fit observatio...  \n",
       "1      Yes, you are missing something. How come age d...  \n",
       "2      C.S.Lewis believes things on faith, yet we are...  \n",
       "3      Well, it might help if you could propose a mec...  \n",
       "4      You really think so? Im flattered, but I think...  \n",
       "...                                                  ...  \n",
       "9995   oh because for the past decade or so they have...  \n",
       "9997   But the embryo is a mere clump of flesh inside...  \n",
       "9998   **\\n Sez u. Your problem being that when you a...  \n",
       "9999     That's what faith does. It limits your options.  \n",
       "10000  On the contrary... These individuals (or indiv...  \n",
       "\n",
       "[8895 rows x 30 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with zipfile.ZipFile('iac_v1.1.zip') as z:\n",
    "   with z.open('iac_v1.1/data/fourforums/annotations/mechanical_turk/qr_averages.csv') as f:\n",
    "      qr = pd.read_csv(f)\n",
    "\n",
    "   with z.open('iac_v1.1/data/fourforums/annotations/mechanical_turk/qr_meta.csv') as f:\n",
    "      md = pd.read_csv(f)\n",
    "\n",
    "# columns = ['key', 'nicenasty', 'questioning-asserting', 'negotiate-attack', 'fact-feeling']\n",
    "# qr_sub = qr[columns]\n",
    "# qr_sub = qr\n",
    "\n",
    "pairs = qr.merge(md, how='inner', on='key')\n",
    "pairs = pairs[~pairs.quote_post_id.isnull() & ~pairs.response_post_id.isnull()]\n",
    "pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a lot of variables! Variables like \"agree-disagree\" are the averages of annotations of the data made by workers on Mechanical Turk. The workers were asked questions like:\n",
    "\n",
    "* __agree-disagree__ (Boolean): Does the respondent agree or disagree with the prior post?\n",
    "* __fact-feeling__  (-5 to 5): Is the respondent attempting to make a fact based argument or appealing to feelings and emotions?\n",
    "* __attack__ (-5 to 5): Is the respondent being supportive/respectful or are they attacking/insulting in their writing?\n",
    "* __sarcasm__ (-5 to 5): Is the respondent using sarcasm?\n",
    "\n",
    "Unfortunately the dataset only has the \"response\" annotated, not the original \"quote.\" However, some \"responses\" in this dataset are also \"quotes,\" meaning we can form triples of quote-response-response. Let's self-merge this dataframe to get these \"r1\" and \"r2\" pairs where both texts have annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quote</th>\n",
       "      <th>response1</th>\n",
       "      <th>response2</th>\n",
       "      <th>attack_r1</th>\n",
       "      <th>fact-feeling_r1</th>\n",
       "      <th>nicenasty_r1</th>\n",
       "      <th>sarcasm_r1</th>\n",
       "      <th>agreement_r2</th>\n",
       "      <th>key_r1</th>\n",
       "      <th>discussion_id_x_r1</th>\n",
       "      <th>agree-disagree_r1</th>\n",
       "      <th>agreement_r1</th>\n",
       "      <th>agreement_unsure_r1</th>\n",
       "      <th>attack_unsure_r1</th>\n",
       "      <th>defeater-undercutter_r1</th>\n",
       "      <th>defeater-undercutter_unsure_r1</th>\n",
       "      <th>fact-feeling_unsure_r1</th>\n",
       "      <th>negotiate-attack_r1</th>\n",
       "      <th>negotiate-attack_unsure_r1</th>\n",
       "      <th>nicenasty_unsure_r1</th>\n",
       "      <th>personal-audience_r1</th>\n",
       "      <th>personal-audience_unsure_r1</th>\n",
       "      <th>questioning-asserting_r1</th>\n",
       "      <th>questioning-asserting_unsure_r1</th>\n",
       "      <th>sarcasm_unsure_r1</th>\n",
       "      <th>discussion_id_y_r1</th>\n",
       "      <th>response_post_id_r1</th>\n",
       "      <th>quote_post_id_r1</th>\n",
       "      <th>term_r1</th>\n",
       "      <th>task1 num annot_r1</th>\n",
       "      <th>task2 num annot_r1</th>\n",
       "      <th>task2 num disagree_r1</th>\n",
       "      <th>key_r2</th>\n",
       "      <th>discussion_id_x_r2</th>\n",
       "      <th>agree-disagree_r2</th>\n",
       "      <th>agreement_unsure_r2</th>\n",
       "      <th>attack_r2</th>\n",
       "      <th>attack_unsure_r2</th>\n",
       "      <th>defeater-undercutter_r2</th>\n",
       "      <th>defeater-undercutter_unsure_r2</th>\n",
       "      <th>fact-feeling_r2</th>\n",
       "      <th>fact-feeling_unsure_r2</th>\n",
       "      <th>negotiate-attack_r2</th>\n",
       "      <th>negotiate-attack_unsure_r2</th>\n",
       "      <th>nicenasty_r2</th>\n",
       "      <th>nicenasty_unsure_r2</th>\n",
       "      <th>personal-audience_r2</th>\n",
       "      <th>personal-audience_unsure_r2</th>\n",
       "      <th>questioning-asserting_r2</th>\n",
       "      <th>questioning-asserting_unsure_r2</th>\n",
       "      <th>sarcasm_r2</th>\n",
       "      <th>sarcasm_unsure_r2</th>\n",
       "      <th>discussion_id_y_r2</th>\n",
       "      <th>response_post_id_r2</th>\n",
       "      <th>quote_post_id_r2</th>\n",
       "      <th>term_r2</th>\n",
       "      <th>task1 num annot_r2</th>\n",
       "      <th>task2 num annot_r2</th>\n",
       "      <th>task2 num disagree_r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I remember looking at the classic evolutionary...</td>\n",
       "      <td>Why do you find it necessary to fit observatio...</td>\n",
       "      <td>Evolution has no goals, it is merely a beautif...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>-2.833333</td>\n",
       "      <td>(731, 1)</td>\n",
       "      <td>6032</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>-1.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>-2.250000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>-4.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>6032</td>\n",
       "      <td>149609</td>\n",
       "      <td>149552.0</td>\n",
       "      <td>None</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>(610, 2)</td>\n",
       "      <td>6032</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>-3.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>6032</td>\n",
       "      <td>149673</td>\n",
       "      <td>149609.0</td>\n",
       "      <td>None</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the fun in that?</td>\n",
       "      <td>Seriously? Well, I come here hoping for someth...</td>\n",
       "      <td>nah, I was just poking fun because I can! Pers...</td>\n",
       "      <td>-0.600000</td>\n",
       "      <td>-2.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.166667</td>\n",
       "      <td>(697, 2)</td>\n",
       "      <td>5205</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>-2.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5205</td>\n",
       "      <td>122800</td>\n",
       "      <td>122780.0</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>(1267, 0)</td>\n",
       "      <td>5205</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>-1.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>5205</td>\n",
       "      <td>123129</td>\n",
       "      <td>122800.0</td>\n",
       "      <td>None</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>First off, the scientific method goes:\\n \\n 1)...</td>\n",
       "      <td>You guys know me. Always happy to correct anyo...</td>\n",
       "      <td>Ah, thanks for the correction, although there ...</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.400000</td>\n",
       "      <td>(9, 0)</td>\n",
       "      <td>9449</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>-2.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>-3.666667</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>9449</td>\n",
       "      <td>247240</td>\n",
       "      <td>247225.0</td>\n",
       "      <td>you</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>(1393, 1)</td>\n",
       "      <td>9449</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>9449</td>\n",
       "      <td>247243</td>\n",
       "      <td>247240.0</td>\n",
       "      <td>No terms in first 10</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You can ignore the obvious question. This is w...</td>\n",
       "      <td>Actually what they are really doing is ignorin...</td>\n",
       "      <td>Really, then show me how I'm wrong - without d...</td>\n",
       "      <td>-3.500000</td>\n",
       "      <td>-3.166667</td>\n",
       "      <td>-3.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>-1.833333</td>\n",
       "      <td>(1077, 1)</td>\n",
       "      <td>3467</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>-4.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-4.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3467</td>\n",
       "      <td>73741</td>\n",
       "      <td>73738.0</td>\n",
       "      <td>actually</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>(622, 1)</td>\n",
       "      <td>3467</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>-1.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>3467</td>\n",
       "      <td>73783</td>\n",
       "      <td>73741.0</td>\n",
       "      <td>really</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Its really sad what these gay predator priests...</td>\n",
       "      <td>Homosexuals are attracted to adults of the sam...</td>\n",
       "      <td>Homosexuals are attracted to people of the sam...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>2.166667</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>-2.666667</td>\n",
       "      <td>(611, 0)</td>\n",
       "      <td>4337</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>-0.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>4337</td>\n",
       "      <td>112008</td>\n",
       "      <td>111931.0</td>\n",
       "      <td>No terms in first 10</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>(1350, 0)</td>\n",
       "      <td>4337</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4337</td>\n",
       "      <td>112012</td>\n",
       "      <td>112008.0</td>\n",
       "      <td>No terms in first 10</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1341</th>\n",
       "      <td>1. Did she do anything wrong?</td>\n",
       "      <td>Yes, she walked down the wrong alley, alone. W...</td>\n",
       "      <td>So it was wrong for her to walk down a public ...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>-3.333333</td>\n",
       "      <td>(27, 4)</td>\n",
       "      <td>13306</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>13306</td>\n",
       "      <td>370461</td>\n",
       "      <td>370385.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>(83, 5)</td>\n",
       "      <td>13306</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>-3.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>-2.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.500000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.666667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>-2.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>13306</td>\n",
       "      <td>370646</td>\n",
       "      <td>370461.0</td>\n",
       "      <td>so</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1342</th>\n",
       "      <td>this is also the reason why atheism is more li...</td>\n",
       "      <td>It is curious how lately christians have been ...</td>\n",
       "      <td>Well, the type of atheism you are talking abou...</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>-2.250000</td>\n",
       "      <td>(1382, 6)</td>\n",
       "      <td>3982</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>-1.285714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>-0.428571</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.714286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>3982</td>\n",
       "      <td>83610</td>\n",
       "      <td>83594.0</td>\n",
       "      <td>No terms in first 10</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>(974, 6)</td>\n",
       "      <td>3982</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3982</td>\n",
       "      <td>83636</td>\n",
       "      <td>83610.0</td>\n",
       "      <td>well</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1343</th>\n",
       "      <td>Assault weapons? first of all, what are assaul...</td>\n",
       "      <td>Thanks Patriot for the well researched respons...</td>\n",
       "      <td>The ban on assault weapons stands on such polt...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>(897, 4)</td>\n",
       "      <td>50</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50</td>\n",
       "      <td>33286</td>\n",
       "      <td>173.0</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>(398, 4)</td>\n",
       "      <td>50</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>-2.60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>-1.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>-0.800000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>50</td>\n",
       "      <td>33347</td>\n",
       "      <td>33286.0</td>\n",
       "      <td>No terms in first 10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1344</th>\n",
       "      <td>And without a gun you're defenseless, why can'...</td>\n",
       "      <td>Hardly any criminals go armed in England, and ...</td>\n",
       "      <td>All of the British papers keep going on about ...</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.800000</td>\n",
       "      <td>(1231, 1)</td>\n",
       "      <td>11999</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>-1.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11999</td>\n",
       "      <td>333578</td>\n",
       "      <td>333574.0</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>(1393, 2)</td>\n",
       "      <td>11999</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>-3.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>-2.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>11999</td>\n",
       "      <td>333583</td>\n",
       "      <td>333578.0</td>\n",
       "      <td>No terms in first 10</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1345</th>\n",
       "      <td>What I don't understand is why YEC's want to L...</td>\n",
       "      <td>That's what faith does. It limits your options.</td>\n",
       "      <td>Here's a nice little Google def: A convinced b...</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>-0.600000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.400000</td>\n",
       "      <td>(1348, 1)</td>\n",
       "      <td>6032</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>6032</td>\n",
       "      <td>149609</td>\n",
       "      <td>149552.0</td>\n",
       "      <td>No terms in first 10</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>(402, 2)</td>\n",
       "      <td>6032</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6032</td>\n",
       "      <td>149673</td>\n",
       "      <td>149609.0</td>\n",
       "      <td>No terms in first 10</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1340 rows Ã— 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  quote  \\\n",
       "0     I remember looking at the classic evolutionary...   \n",
       "1                              What is the fun in that?   \n",
       "2     First off, the scientific method goes:\\n \\n 1)...   \n",
       "3     You can ignore the obvious question. This is w...   \n",
       "4     Its really sad what these gay predator priests...   \n",
       "...                                                 ...   \n",
       "1341                      1. Did she do anything wrong?   \n",
       "1342  this is also the reason why atheism is more li...   \n",
       "1343  Assault weapons? first of all, what are assaul...   \n",
       "1344  And without a gun you're defenseless, why can'...   \n",
       "1345  What I don't understand is why YEC's want to L...   \n",
       "\n",
       "                                              response1  \\\n",
       "0     Why do you find it necessary to fit observatio...   \n",
       "1     Seriously? Well, I come here hoping for someth...   \n",
       "2     You guys know me. Always happy to correct anyo...   \n",
       "3     Actually what they are really doing is ignorin...   \n",
       "4     Homosexuals are attracted to adults of the sam...   \n",
       "...                                                 ...   \n",
       "1341  Yes, she walked down the wrong alley, alone. W...   \n",
       "1342  It is curious how lately christians have been ...   \n",
       "1343  Thanks Patriot for the well researched respons...   \n",
       "1344  Hardly any criminals go armed in England, and ...   \n",
       "1345    That's what faith does. It limits your options.   \n",
       "\n",
       "                                              response2  attack_r1  \\\n",
       "0     Evolution has no goals, it is merely a beautif...   0.333333   \n",
       "1     nah, I was just poking fun because I can! Pers...  -0.600000   \n",
       "2     Ah, thanks for the correction, although there ...   2.400000   \n",
       "3     Really, then show me how I'm wrong - without d...  -3.500000   \n",
       "4     Homosexuals are attracted to people of the sam...   0.166667   \n",
       "...                                                 ...        ...   \n",
       "1341  So it was wrong for her to walk down a public ...   0.166667   \n",
       "1342  Well, the type of atheism you are talking abou...   1.200000   \n",
       "1343  The ban on assault weapons stands on such polt...   2.000000   \n",
       "1344  All of the British papers keep going on about ...   2.400000   \n",
       "1345  Here's a nice little Google def: A convinced b...   0.600000   \n",
       "\n",
       "      fact-feeling_r1  nicenasty_r1  sarcasm_r1  agreement_r2     key_r1  \\\n",
       "0            0.333333      0.666667    0.200000     -2.833333   (731, 1)   \n",
       "1           -2.200000      0.000000    0.000000     -2.166667   (697, 2)   \n",
       "2            2.800000      2.200000    0.000000     -0.400000     (9, 0)   \n",
       "3           -3.166667     -3.166667    0.166667     -1.833333  (1077, 1)   \n",
       "4            2.166667     -0.166667    0.400000     -2.666667   (611, 0)   \n",
       "...               ...           ...         ...           ...        ...   \n",
       "1341         0.166667      0.500000    0.333333     -3.333333    (27, 4)   \n",
       "1342         0.800000      0.600000    0.250000     -2.250000  (1382, 6)   \n",
       "1343         2.000000      2.500000    0.000000      0.200000   (897, 4)   \n",
       "1344         2.000000      2.600000    0.000000     -2.800000  (1231, 1)   \n",
       "1345        -0.600000      0.600000    0.000000     -2.400000  (1348, 1)   \n",
       "\n",
       "      discussion_id_x_r1  agree-disagree_r1  agreement_r1  \\\n",
       "0                   6032           0.333333     -1.333333   \n",
       "1                   5205           0.833333     -2.400000   \n",
       "2                   9449           0.400000      0.600000   \n",
       "3                   3467           0.400000     -4.333333   \n",
       "4                   4337           0.333333     -2.000000   \n",
       "...                  ...                ...           ...   \n",
       "1341               13306           0.800000      0.666667   \n",
       "1342                3982           0.000000     -1.000000   \n",
       "1343                  50           0.833333      0.500000   \n",
       "1344               11999           0.285714     -1.600000   \n",
       "1345                6032           0.857143      0.800000   \n",
       "\n",
       "      agreement_unsure_r1  attack_unsure_r1  defeater-undercutter_r1  \\\n",
       "0                0.333333          0.000000                 0.500000   \n",
       "1                0.000000          0.000000                -5.000000   \n",
       "2                0.200000          0.200000                -2.666667   \n",
       "3                0.000000          0.000000                -4.666667   \n",
       "4                0.166667          0.166667                -0.750000   \n",
       "...                   ...               ...                      ...   \n",
       "1341             0.166667          0.166667                 0.000000   \n",
       "1342             0.200000          0.200000                -1.285714   \n",
       "1343             0.000000          0.000000                 1.000000   \n",
       "1344             0.000000          0.000000                 1.200000   \n",
       "1345             0.600000          0.200000                 3.000000   \n",
       "\n",
       "      defeater-undercutter_unsure_r1  fact-feeling_unsure_r1  \\\n",
       "0                                0.0                0.333333   \n",
       "1                                0.0                0.000000   \n",
       "2                                0.0                0.200000   \n",
       "3                                0.0                0.000000   \n",
       "4                                0.0                0.166667   \n",
       "...                              ...                     ...   \n",
       "1341                             0.0                0.166667   \n",
       "1342                             0.0                0.200000   \n",
       "1343                             0.0                0.000000   \n",
       "1344                             0.0                0.000000   \n",
       "1345                             0.0                0.400000   \n",
       "\n",
       "      negotiate-attack_r1  negotiate-attack_unsure_r1  nicenasty_unsure_r1  \\\n",
       "0                3.000000                        0.25             0.166667   \n",
       "1                2.000000                        0.00             0.000000   \n",
       "2               -3.666667                        0.00             0.200000   \n",
       "3               -0.666667                        0.00             0.000000   \n",
       "4               -2.000000                        0.00             0.166667   \n",
       "...                   ...                         ...                  ...   \n",
       "1341            -1.000000                        0.00             0.166667   \n",
       "1342            -0.428571                        0.00             0.200000   \n",
       "1343             1.000000                        0.00             0.000000   \n",
       "1344            -1.000000                        0.00             0.000000   \n",
       "1345            -3.000000                        0.00             0.200000   \n",
       "\n",
       "      personal-audience_r1  personal-audience_unsure_r1  \\\n",
       "0                -2.250000                         0.25   \n",
       "1                 0.000000                         0.00   \n",
       "2                 0.333333                         0.00   \n",
       "3                -2.000000                         0.00   \n",
       "4                 0.000000                         0.00   \n",
       "...                    ...                          ...   \n",
       "1341              0.000000                         0.00   \n",
       "1342              0.857143                         0.00   \n",
       "1343              4.000000                         0.00   \n",
       "1344              0.000000                         0.00   \n",
       "1345              3.000000                         0.00   \n",
       "\n",
       "      questioning-asserting_r1  questioning-asserting_unsure_r1  \\\n",
       "0                    -4.250000                              0.0   \n",
       "1                    -2.000000                              0.0   \n",
       "2                     3.666667                              0.0   \n",
       "3                     3.000000                              0.0   \n",
       "4                     3.750000                              0.0   \n",
       "...                        ...                              ...   \n",
       "1341                  0.000000                              0.0   \n",
       "1342                  1.714286                              0.0   \n",
       "1343                  1.000000                              0.0   \n",
       "1344                 -0.200000                              0.0   \n",
       "1345                  3.000000                              0.0   \n",
       "\n",
       "      sarcasm_unsure_r1  discussion_id_y_r1  response_post_id_r1  \\\n",
       "0              0.166667                6032               149609   \n",
       "1              0.000000                5205               122800   \n",
       "2              0.200000                9449               247240   \n",
       "3              0.000000                3467                73741   \n",
       "4              0.166667                4337               112008   \n",
       "...                 ...                 ...                  ...   \n",
       "1341           0.500000               13306               370461   \n",
       "1342           0.200000                3982                83610   \n",
       "1343           0.000000                  50                33286   \n",
       "1344           0.000000               11999               333578   \n",
       "1345           0.200000                6032               149609   \n",
       "\n",
       "      quote_post_id_r1               term_r1  task1 num annot_r1  \\\n",
       "0             149552.0                  None                   6   \n",
       "1             122780.0                  None                   5   \n",
       "2             247225.0                   you                   5   \n",
       "3              73738.0              actually                   6   \n",
       "4             111931.0  No terms in first 10                   6   \n",
       "...                ...                   ...                 ...   \n",
       "1341          370385.0                   yes                   6   \n",
       "1342           83594.0  No terms in first 10                   5   \n",
       "1343             173.0                  None                   4   \n",
       "1344          333574.0                  None                   5   \n",
       "1345          149552.0  No terms in first 10                   5   \n",
       "\n",
       "      task2 num annot_r1  task2 num disagree_r1     key_r2  \\\n",
       "0                      6                      4   (610, 2)   \n",
       "1                      6                      1  (1267, 0)   \n",
       "2                      5                      3  (1393, 1)   \n",
       "3                      5                      3   (622, 1)   \n",
       "4                      6                      4  (1350, 0)   \n",
       "...                  ...                    ...        ...   \n",
       "1341                   5                      1    (83, 5)   \n",
       "1342                   7                      7   (974, 6)   \n",
       "1343                   6                      1   (398, 4)   \n",
       "1344                   7                      5  (1393, 2)   \n",
       "1345                   7                      1   (402, 2)   \n",
       "\n",
       "      discussion_id_x_r2  agree-disagree_r2  agreement_unsure_r2  attack_r2  \\\n",
       "0                   6032           0.600000             0.166667   0.333333   \n",
       "1                   5205           0.600000             0.333333   0.833333   \n",
       "2                   9449           1.000000             0.200000   0.800000   \n",
       "3                   3467           0.600000             0.166667  -1.333333   \n",
       "4                   4337           0.428571             0.000000   1.166667   \n",
       "...                  ...                ...                  ...        ...   \n",
       "1341               13306           0.200000             0.166667  -3.166667   \n",
       "1342                3982           0.600000             0.250000   0.750000   \n",
       "1343                  50           0.000000             0.600000   2.200000   \n",
       "1344               11999           0.571429             0.200000   0.200000   \n",
       "1345                6032           0.428571             0.200000   1.000000   \n",
       "\n",
       "      attack_unsure_r2  defeater-undercutter_r2  \\\n",
       "0             0.166667                    -3.50   \n",
       "1             0.166667                    -1.50   \n",
       "2             0.200000                      NaN   \n",
       "3             0.166667                     2.50   \n",
       "4             0.000000                    -2.50   \n",
       "...                ...                      ...   \n",
       "1341          0.166667                    -2.75   \n",
       "1342          0.250000                     2.50   \n",
       "1343          0.400000                    -2.60   \n",
       "1344          0.200000                    -3.00   \n",
       "1345          0.000000                    -0.25   \n",
       "\n",
       "      defeater-undercutter_unsure_r2  fact-feeling_r2  fact-feeling_unsure_r2  \\\n",
       "0                                0.0         1.333333                0.166667   \n",
       "1                                0.0        -1.333333                0.500000   \n",
       "2                                NaN         1.200000                0.200000   \n",
       "3                                0.0         0.333333                0.166667   \n",
       "4                                0.0         0.666667                0.000000   \n",
       "...                              ...              ...                     ...   \n",
       "1341                             0.0        -3.500000                0.166667   \n",
       "1342                             0.0         1.000000                0.250000   \n",
       "1343                             0.0         1.800000                0.400000   \n",
       "1344                             0.0         0.400000                0.200000   \n",
       "1345                             0.0         0.600000                0.000000   \n",
       "\n",
       "      negotiate-attack_r2  negotiate-attack_unsure_r2  nicenasty_r2  \\\n",
       "0                3.500000                         0.0      0.500000   \n",
       "1                2.000000                         0.0      0.500000   \n",
       "2                     NaN                         NaN      1.000000   \n",
       "3                1.500000                         0.0      0.000000   \n",
       "4               -1.750000                         0.0      1.166667   \n",
       "...                   ...                         ...           ...   \n",
       "1341             1.500000                         0.0     -2.666667   \n",
       "1342            -3.000000                         0.0      1.750000   \n",
       "1343            -1.200000                         0.0      1.200000   \n",
       "1344            -0.333333                         0.0      0.200000   \n",
       "1345            -3.000000                         0.0      1.200000   \n",
       "\n",
       "      nicenasty_unsure_r2  personal-audience_r2  personal-audience_unsure_r2  \\\n",
       "0                0.333333             -4.000000                          0.0   \n",
       "1                0.166667             -3.000000                          0.0   \n",
       "2                0.400000                   NaN                          NaN   \n",
       "3                0.166667              0.000000                          0.0   \n",
       "4                0.000000             -1.250000                          0.0   \n",
       "...                   ...                   ...                          ...   \n",
       "1341             0.166667             -2.250000                          0.0   \n",
       "1342             0.250000             -3.000000                          0.0   \n",
       "1343             0.400000             -0.800000                          0.0   \n",
       "1344             0.200000             -2.666667                          0.0   \n",
       "1345             0.000000             -0.500000                          0.0   \n",
       "\n",
       "      questioning-asserting_r2  questioning-asserting_unsure_r2  sarcasm_r2  \\\n",
       "0                     1.500000                              0.0         0.0   \n",
       "1                    -1.500000                              0.0         0.2   \n",
       "2                          NaN                              NaN         0.0   \n",
       "3                    -1.500000                              0.0         0.2   \n",
       "4                     3.250000                              0.0         0.0   \n",
       "...                        ...                              ...         ...   \n",
       "1341                 -0.750000                              0.0         0.2   \n",
       "1342                  2.500000                              0.0         0.0   \n",
       "1343                  2.000000                              0.0         0.0   \n",
       "1344                 -0.333333                              0.0         0.0   \n",
       "1345                  3.250000                              0.0         0.2   \n",
       "\n",
       "      sarcasm_unsure_r2  discussion_id_y_r2  response_post_id_r2  \\\n",
       "0              0.166667                6032               149673   \n",
       "1              0.166667                5205               123129   \n",
       "2              0.400000                9449               247243   \n",
       "3              0.166667                3467                73783   \n",
       "4              0.000000                4337               112012   \n",
       "...                 ...                 ...                  ...   \n",
       "1341           0.166667               13306               370646   \n",
       "1342           0.000000                3982                83636   \n",
       "1343           0.200000                  50                33347   \n",
       "1344           0.400000               11999               333583   \n",
       "1345           0.000000                6032               149673   \n",
       "\n",
       "      quote_post_id_r2               term_r2  task1 num annot_r2  \\\n",
       "0             149609.0                  None                   6   \n",
       "1             122800.0                  None                   6   \n",
       "2             247240.0  No terms in first 10                   5   \n",
       "3              73741.0                really                   6   \n",
       "4             112008.0  No terms in first 10                   6   \n",
       "...                ...                   ...                 ...   \n",
       "1341          370461.0                    so                   6   \n",
       "1342           83610.0                  well                   4   \n",
       "1343           33286.0  No terms in first 10                   5   \n",
       "1344          333578.0  No terms in first 10                   5   \n",
       "1345          149609.0  No terms in first 10                   5   \n",
       "\n",
       "      task2 num annot_r2  task2 num disagree_r2  \n",
       "0                      5                      2  \n",
       "1                      5                      2  \n",
       "2                      7                      0  \n",
       "3                      5                      2  \n",
       "4                      7                      4  \n",
       "...                  ...                    ...  \n",
       "1341                   5                      4  \n",
       "1342                   5                      2  \n",
       "1343                   5                      5  \n",
       "1344                   7                      3  \n",
       "1345                   7                      4  \n",
       "\n",
       "[1340 rows x 59 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Self-merge where the 'response' matches another 'quote' in the DataFrame\n",
    "triples = pairs.merge(pairs,left_on='response',right_on='quote',how='inner',suffixes=('_r1','_r2'))\n",
    "\n",
    "# Rename and reorder columns\n",
    "triples = triples.rename(columns={'quote_r1':'quote', 'quote_r2':'response1', 'response_r2':'response2'})\n",
    "triples = triples.drop(columns=['response_r1'])\n",
    "front_columns = [\n",
    "                 'quote','response1','response2','attack_r1','fact-feeling_r1','nicenasty_r1','sarcasm_r1',\n",
    "                 'agreement_r2'\n",
    "                ]\n",
    "triples = triples.dropna(subset=front_columns)\n",
    "triples = triples[front_columns].join(triples.drop(columns=front_columns))\n",
    "\n",
    "# Display triples\n",
    "triples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have 1,346 triples of quote-response1-response2, several text variables of response1 (e.g., \"Is the respondent using sarcasm?\") that may predict the agreement of response2. In other words: _Does a sarcastic comment lead to more agreement?_ Of course, as with almost all observational data, there are a number of confounders that make our identification difficult, but for now, let's see how to run a simple regression in Python of agreement_r2 (dependent variable, commonly known as Y) on sarcasm_r1. Fortunately, we do have a strong case for identifying the direction of causality: Because response1 comes before response2, we can rule out the possibility that response2 affects response1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>      <td>agreement_r2</td>   <th>  R-squared:         </th> <td>   0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>  -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td> 0.03364</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 06 Feb 2022</td> <th>  Prob (F-statistic):</th>  <td> 0.855</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>08:10:32</td>     <th>  Log-Likelihood:    </th> <td> -2581.1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1340</td>      <th>  AIC:               </th> <td>   5166.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1338</td>      <th>  BIC:               </th> <td>   5177.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>      <td>   -1.2805</td> <td>    0.058</td> <td>  -22.263</td> <td> 0.000</td> <td>   -1.393</td> <td>   -1.168</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sarcasm_r1</th> <td>   -0.0383</td> <td>    0.209</td> <td>   -0.183</td> <td> 0.855</td> <td>   -0.448</td> <td>    0.371</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>86.710</td> <th>  Durbin-Watson:     </th> <td>   1.866</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td> 102.903</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.642</td> <th>  Prob(JB):          </th> <td>4.52e-23</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.443</td> <th>  Cond. No.          </th> <td>    4.73</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:           agreement_r2   R-squared:                       0.000\n",
       "Model:                            OLS   Adj. R-squared:                 -0.001\n",
       "Method:                 Least Squares   F-statistic:                   0.03364\n",
       "Date:                Sun, 06 Feb 2022   Prob (F-statistic):              0.855\n",
       "Time:                        08:10:32   Log-Likelihood:                -2581.1\n",
       "No. Observations:                1340   AIC:                             5166.\n",
       "Df Residuals:                    1338   BIC:                             5177.\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         -1.2805      0.058    -22.263      0.000      -1.393      -1.168\n",
       "sarcasm_r1    -0.0383      0.209     -0.183      0.855      -0.448       0.371\n",
       "==============================================================================\n",
       "Omnibus:                       86.710   Durbin-Watson:                   1.866\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              102.903\n",
       "Skew:                           0.642   Prob(JB):                     4.52e-23\n",
       "Kurtosis:                       3.443   Cond. No.                         4.73\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We build an Ordinary Least Squares (OLS) model of agreement_r2 on sarcasm_r1.\n",
    "# The function sm.add_constant() adds an intercept term to the regression (e.g., b in y = ax + b)\n",
    "y = triples['agreement_r2']\n",
    "X_cols = ['sarcasm_r1']\n",
    "X = sm.add_constant(triples[X_cols])\n",
    "\n",
    "lm1 = sm.OLS(y,X).fit()\n",
    "lm1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The p-value for sarcasm_r1 is 0.855, which means we fail to reject the null hypothesis that there is no effect of sarcasm on agreement. However, we have other variables that may be confounding the effect of pure \"attack\" or pure \"sarcasm.\" Let's try adding 3 other annotations to the regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>      <td>agreement_r2</td>   <th>  R-squared:         </th> <td>   0.036</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.034</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   12.60</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 06 Feb 2022</td> <th>  Prob (F-statistic):</th> <td>4.54e-10</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>08:15:59</td>     <th>  Log-Likelihood:    </th> <td> -2556.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1340</td>      <th>  AIC:               </th> <td>   5123.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1335</td>      <th>  BIC:               </th> <td>   5149.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "         <td></td>            <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>           <td>   -1.5276</td> <td>    0.075</td> <td>  -20.497</td> <td> 0.000</td> <td>   -1.674</td> <td>   -1.381</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>attack_r1</th>       <td>    0.1808</td> <td>    0.073</td> <td>    2.475</td> <td> 0.013</td> <td>    0.038</td> <td>    0.324</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fact-feeling_r1</th> <td>   -0.0248</td> <td>    0.033</td> <td>   -0.742</td> <td> 0.458</td> <td>   -0.090</td> <td>    0.041</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>nicenasty_r1</th>    <td>    0.0748</td> <td>    0.079</td> <td>    0.951</td> <td> 0.342</td> <td>   -0.079</td> <td>    0.229</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sarcasm_r1</th>      <td>    0.6972</td> <td>    0.240</td> <td>    2.905</td> <td> 0.004</td> <td>    0.226</td> <td>    1.168</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>86.269</td> <th>  Durbin-Watson:     </th> <td>   1.896</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td> 103.200</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.629</td> <th>  Prob(JB):          </th> <td>3.89e-23</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.517</td> <th>  Cond. No.          </th> <td>    12.8</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:           agreement_r2   R-squared:                       0.036\n",
       "Model:                            OLS   Adj. R-squared:                  0.034\n",
       "Method:                 Least Squares   F-statistic:                     12.60\n",
       "Date:                Sun, 06 Feb 2022   Prob (F-statistic):           4.54e-10\n",
       "Time:                        08:15:59   Log-Likelihood:                -2556.3\n",
       "No. Observations:                1340   AIC:                             5123.\n",
       "Df Residuals:                    1335   BIC:                             5149.\n",
       "Df Model:                           4                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===================================================================================\n",
       "                      coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-----------------------------------------------------------------------------------\n",
       "const              -1.5276      0.075    -20.497      0.000      -1.674      -1.381\n",
       "attack_r1           0.1808      0.073      2.475      0.013       0.038       0.324\n",
       "fact-feeling_r1    -0.0248      0.033     -0.742      0.458      -0.090       0.041\n",
       "nicenasty_r1        0.0748      0.079      0.951      0.342      -0.079       0.229\n",
       "sarcasm_r1          0.6972      0.240      2.905      0.004       0.226       1.168\n",
       "==============================================================================\n",
       "Omnibus:                       86.269   Durbin-Watson:                   1.896\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              103.200\n",
       "Skew:                           0.629   Prob(JB):                     3.89e-23\n",
       "Kurtosis:                       3.517   Cond. No.                         12.8\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = triples['agreement_r2']\n",
    "X_cols = ['attack_r1','fact-feeling_r1','nicenasty_r1','sarcasm_r1']\n",
    "X = sm.add_constant(triples[X_cols])\n",
    "\n",
    "lm2 = sm.OLS(y,X).fit()\n",
    "lm2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The condition number (bottom-right of the output above) is 12.8, indicating high correlations between our predictors. This is one of many issues to look out for when running regressions. Let's take a look at the correlations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "corr_matrix = np.corrcoef(triples[X_cols].T)\n",
    "smg.plot_corr(corr_matrix, xnames=X_cols)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's very high correlatio between attack_r1 and nicenasty_r1! We found a significant effect of attack_r1, but not of nicenasty_r1. If we remove attack_r1 from the model, do you think nicenasty_r1 will be significant?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>      <td>agreement_r2</td>   <th>  R-squared:         </th> <td>   0.032</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.030</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   14.71</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 06 Feb 2022</td> <th>  Prob (F-statistic):</th> <td>2.00e-09</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>08:18:03</td>     <th>  Log-Likelihood:    </th> <td> -2559.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1340</td>      <th>  AIC:               </th> <td>   5127.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1336</td>      <th>  BIC:               </th> <td>   5147.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "         <td></td>            <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>           <td>   -1.5744</td> <td>    0.072</td> <td>  -21.798</td> <td> 0.000</td> <td>   -1.716</td> <td>   -1.433</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fact-feeling_r1</th> <td>   -0.0183</td> <td>    0.033</td> <td>   -0.548</td> <td> 0.584</td> <td>   -0.084</td> <td>    0.047</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>nicenasty_r1</th>    <td>    0.2454</td> <td>    0.038</td> <td>    6.488</td> <td> 0.000</td> <td>    0.171</td> <td>    0.320</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sarcasm_r1</th>      <td>    0.7113</td> <td>    0.240</td> <td>    2.959</td> <td> 0.003</td> <td>    0.240</td> <td>    1.183</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>85.105</td> <th>  Durbin-Watson:     </th> <td>   1.893</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td> 101.648</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.623</td> <th>  Prob(JB):          </th> <td>8.46e-23</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.518</td> <th>  Cond. No.          </th> <td>    10.3</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:           agreement_r2   R-squared:                       0.032\n",
       "Model:                            OLS   Adj. R-squared:                  0.030\n",
       "Method:                 Least Squares   F-statistic:                     14.71\n",
       "Date:                Sun, 06 Feb 2022   Prob (F-statistic):           2.00e-09\n",
       "Time:                        08:18:03   Log-Likelihood:                -2559.3\n",
       "No. Observations:                1340   AIC:                             5127.\n",
       "Df Residuals:                    1336   BIC:                             5147.\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===================================================================================\n",
       "                      coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-----------------------------------------------------------------------------------\n",
       "const              -1.5744      0.072    -21.798      0.000      -1.716      -1.433\n",
       "fact-feeling_r1    -0.0183      0.033     -0.548      0.584      -0.084       0.047\n",
       "nicenasty_r1        0.2454      0.038      6.488      0.000       0.171       0.320\n",
       "sarcasm_r1          0.7113      0.240      2.959      0.003       0.240       1.183\n",
       "==============================================================================\n",
       "Omnibus:                       85.105   Durbin-Watson:                   1.893\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              101.648\n",
       "Skew:                           0.623   Prob(JB):                     8.46e-23\n",
       "Kurtosis:                       3.518   Cond. No.                         10.3\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = triples['agreement_r2']\n",
    "X_cols = ['fact-feeling_r1','nicenasty_r1','sarcasm_r1']\n",
    "X = sm.add_constant(triples[X_cols])\n",
    "\n",
    "lm2 = sm.OLS(y,X).fit()\n",
    "lm2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, it is! And the t-value is even larger (i.e., stronger evidence of an effect). With this new regression model, we see a significant effect from attack_r1/nicenasty_r1 and sarcasm_r1, indicating both of these dimensions affect whether the response2 agrees with response1. Note that the coefficients are both positive: For attack_r1/nicenasty_r1, this means that a more \"supportive/respectful\" comment led to more agreement, and for sarcasm_r1, this means that a more sarcasistic comment led to more agreement! Is that surprising?\n",
    "\n",
    "For good measure, we can add other variables ourselves, such as sentiment and the character length of the comment. The length may be particularly important because of how it affects the annotations of Mechanical Turk workers. For example, as I was skimming through the data, it seemed like shorter comments were being rated as more supportive/respectful, even if this was not the case on a per-word basis. For sentiment, let's use the convenient BERT pipeline we used last week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "triples['length_r1'] = triples['response1'].apply(lambda x: len(x))\n",
    "triples['length_r2'] = triples['response2'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: NEGATIVE, with score: 0.9991\n"
     ]
    }
   ],
   "source": [
    "sentiment = pipeline(\"sentiment-analysis\")\n",
    "result = sentiment(\"I hate you\")[0]\n",
    "print(f\"label: {result['label']}, with score: {round(result['score'], 4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This version of BERT is built only for texts of up to 512 tokens, so for comments longer than that, we truncate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "triples['sentiment_r1'] = triples['response1'].apply(lambda x: sentiment(x[:512])[0]['score'])\n",
    "triples['sentiment_r2'] = triples['response2'].apply(lambda x: sentiment(x[:512])[0]['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>      <td>agreement_r2</td>   <th>  R-squared:         </th> <td>   0.033</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.029</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   9.032</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 06 Feb 2022</td> <th>  Prob (F-statistic):</th> <td>1.87e-08</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>08:25:34</td>     <th>  Log-Likelihood:    </th> <td> -2558.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1340</td>      <th>  AIC:               </th> <td>   5130.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1334</td>      <th>  BIC:               </th> <td>   5161.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "         <td></td>            <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>           <td>   -1.3211</td> <td>    0.522</td> <td>   -2.531</td> <td> 0.011</td> <td>   -2.345</td> <td>   -0.297</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fact-feeling_r1</th> <td>   -0.0126</td> <td>    0.034</td> <td>   -0.370</td> <td> 0.711</td> <td>   -0.079</td> <td>    0.054</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>nicenasty_r1</th>    <td>    0.2433</td> <td>    0.038</td> <td>    6.419</td> <td> 0.000</td> <td>    0.169</td> <td>    0.318</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sarcasm_r1</th>      <td>    0.6985</td> <td>    0.241</td> <td>    2.901</td> <td> 0.004</td> <td>    0.226</td> <td>    1.171</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>length_r1</th>       <td>   -0.0001</td> <td>    0.000</td> <td>   -0.935</td> <td> 0.350</td> <td>   -0.000</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sentiment_r1</th>    <td>   -0.2225</td> <td>    0.534</td> <td>   -0.417</td> <td> 0.677</td> <td>   -1.270</td> <td>    0.825</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>85.913</td> <th>  Durbin-Watson:     </th> <td>   1.890</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td> 102.861</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.626</td> <th>  Prob(JB):          </th> <td>4.61e-23</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.526</td> <th>  Cond. No.          </th> <td>7.04e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 7.04e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:           agreement_r2   R-squared:                       0.033\n",
       "Model:                            OLS   Adj. R-squared:                  0.029\n",
       "Method:                 Least Squares   F-statistic:                     9.032\n",
       "Date:                Sun, 06 Feb 2022   Prob (F-statistic):           1.87e-08\n",
       "Time:                        08:25:34   Log-Likelihood:                -2558.8\n",
       "No. Observations:                1340   AIC:                             5130.\n",
       "Df Residuals:                    1334   BIC:                             5161.\n",
       "Df Model:                           5                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===================================================================================\n",
       "                      coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-----------------------------------------------------------------------------------\n",
       "const              -1.3211      0.522     -2.531      0.011      -2.345      -0.297\n",
       "fact-feeling_r1    -0.0126      0.034     -0.370      0.711      -0.079       0.054\n",
       "nicenasty_r1        0.2433      0.038      6.419      0.000       0.169       0.318\n",
       "sarcasm_r1          0.6985      0.241      2.901      0.004       0.226       1.171\n",
       "length_r1          -0.0001      0.000     -0.935      0.350      -0.000       0.000\n",
       "sentiment_r1       -0.2225      0.534     -0.417      0.677      -1.270       0.825\n",
       "==============================================================================\n",
       "Omnibus:                       85.913   Durbin-Watson:                   1.890\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              102.861\n",
       "Skew:                           0.626   Prob(JB):                     4.61e-23\n",
       "Kurtosis:                       3.526   Cond. No.                     7.04e+03\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 7.04e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = triples['agreement_r2']\n",
    "X_cols = ['fact-feeling_r1','nicenasty_r1','sarcasm_r1','length_r1','sentiment_r1']\n",
    "X = sm.add_constant(triples[X_cols])\n",
    "\n",
    "lm2 = sm.OLS(y,X).fit()\n",
    "lm2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "corr_matrix = np.corrcoef(triples[X_cols].T)\n",
    "smg.plot_corr(corr_matrix, xnames=X_cols)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The condition number is high, but our correlatons seem okay. Overall, our finding of significant effects for attack_r1/nicenasty_r1 and sarcasm_r1 persists even with these new controls! This sort of robustness or sensitivity analysis is important for making sure your finding is compelling to yourself and to your audience. Consider doing other robustness checks, such as standardizing these variables before running the regression or adding [robust standard errors](https://en.wikipedia.org/wiki/Heteroscedasticity-consistent_standard_errors). (To put a finer point on it, the analysis above would probably not be sufficient for a peer-reviewed journal, especially as proof of a causal effect.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">*Exercise 1*</font>\n",
    "\n",
    "<font color=\"red\">Propose a simple causal model in your data, or a different causal model in the annotated Internet Arguments Corpus (e.g., a different treatment, a different outcome), and test it using a linear regression. If you are using social media data for your final project, we encourage you to classify or annotate that data (either compuationally or with human annotators) and look at the effect of texts on replies to that text (e.g., Reddit posts on Reddit comments, Tweets on Twitter replies, YouTube video transcripts on YouTube comments). You do not need to make a graph of the causal model, but please make it clear (e.g., \"X affects Y, and C affects both X and Y.\").\n",
    "    \n",
    "<font color=\"red\">***Stretch*** (not required): Propose a more robust identification strategy using either matching, difference in difference, regression discontinuity, or an instrumental variable. Each of these methods usually gives you a more precise identification of the causal effect than a plain regression. Scott Cunningham's [Causal Inference: The Mixtape](https://mixtape.scunning.com/) is a free textbook on these topics, and all of them have good YouTube video explanations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting training and test text\n",
    "Above, we used a number of external measures of text, meaning that the measures were developed without any influence from this dataset. For the annotations, it was Mechanical Turk workers measuring the text. For length, that is just a mathematical count of characters. For sentiment, that BERT model was not trained on this Internet Arguments Corpus.\n",
    "\n",
    "However, this is not always the case. Consider if we want to make a measure of the text based on topic modeling. We build an LDA topic model of these comments, then we measure what number of words from Topic 1 each comment uses. Can we put that measure in the regression? Unfortunately it would lead to a biased estimate of the true effect size because our measure is no longer external. The measure and the model are double-dipping the textual information. This is important to keep in mind for your final projects, and for a more thorough explanation and justification, you can read more about this in [Egami et al. 2018](https://arxiv.org/pdf/1802.02163.pdf).\n",
    "\n",
    "One approach to this in the Internet Arguments Corpus would be to build the measures with the `pairs` that were not also `triples`. Sometimes we have excess data like this that is similar enough to our regression data, which we can use without reducing our regression sample size. For example, you could abductively generate a keyword-count measure like \"argumentativeness\" or \"thoughtfulness\" from non-triple pairs that isn't already in the annotations, and then count the keywords in the triples. This would avoid contamination."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">*Exercise 2*</font>\n",
    "\n",
    "<font color=\"red\">Propose a measure you could generate to fill in or improve upon the simple causal model you proposed above and how you would split the data (e.g., a % of your main data, a separate-but-informative dataset). You do not have to produce the measure.\n",
    "    \n",
    "<font color=\"red\">***Stretch*** (not required): Produce the measure and integrate it into your statistical analysis. This could be a great approach for your final project!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text as mediator\n",
    "\n",
    "What if text is instead the _mediator_, meaning it is effected by the teatment and effects the outcome? Let's briefly return to the Internet Arguments Corpus triples and model the effect of the first comment (\"quote\") on the third comment (\"response2\") mediated by the second comment (\"response1\"). Unfortunately we don't have Turker annotations for the first comment, but we can propose a simple mediation model for the propogation of comment length from first to second to third. In other words: _Is there a causal chain of comment length through a conversation?_\n",
    "\n",
    "A two-step mediation model consists of two linear models, one for each step. Let's create length_q and sentiment_q variables for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "triples['length_q'] = triples['quote'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "triples['sentiment_q'] = triples['quote'].apply(lambda x: sentiment(x[:512])[0]['score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run this analysis, statsmodel (sm) has a convenient `Mediation` module that takes in two linear models and outputs a mediation model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Estimate</th>\n",
       "      <th>Lower CI bound</th>\n",
       "      <th>Upper CI bound</th>\n",
       "      <th>P-value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ACME (control)</th>\n",
       "      <td>-0.023876</td>\n",
       "      <td>-7.728465</td>\n",
       "      <td>7.182894</td>\n",
       "      <td>0.986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACME (treated)</th>\n",
       "      <td>-0.023876</td>\n",
       "      <td>-7.728465</td>\n",
       "      <td>7.182894</td>\n",
       "      <td>0.986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADE (control)</th>\n",
       "      <td>0.073257</td>\n",
       "      <td>0.023600</td>\n",
       "      <td>0.127048</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADE (treated)</th>\n",
       "      <td>0.073257</td>\n",
       "      <td>0.023600</td>\n",
       "      <td>0.127048</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total effect</th>\n",
       "      <td>0.049381</td>\n",
       "      <td>-7.657838</td>\n",
       "      <td>7.236973</td>\n",
       "      <td>0.960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prop. mediated (control)</th>\n",
       "      <td>0.993276</td>\n",
       "      <td>0.559691</td>\n",
       "      <td>1.348486</td>\n",
       "      <td>0.026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prop. mediated (treated)</th>\n",
       "      <td>0.993276</td>\n",
       "      <td>0.559691</td>\n",
       "      <td>1.348486</td>\n",
       "      <td>0.026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACME (average)</th>\n",
       "      <td>-0.023876</td>\n",
       "      <td>-7.728465</td>\n",
       "      <td>7.182894</td>\n",
       "      <td>0.986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADE (average)</th>\n",
       "      <td>0.073257</td>\n",
       "      <td>0.023600</td>\n",
       "      <td>0.127048</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prop. mediated (average)</th>\n",
       "      <td>0.993276</td>\n",
       "      <td>0.559691</td>\n",
       "      <td>1.348486</td>\n",
       "      <td>0.026</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Estimate  Lower CI bound  Upper CI bound  P-value\n",
       "ACME (control)           -0.023876       -7.728465        7.182894    0.986\n",
       "ACME (treated)           -0.023876       -7.728465        7.182894    0.986\n",
       "ADE (control)             0.073257        0.023600        0.127048    0.010\n",
       "ADE (treated)             0.073257        0.023600        0.127048    0.010\n",
       "Total effect              0.049381       -7.657838        7.236973    0.960\n",
       "Prop. mediated (control)  0.993276        0.559691        1.348486    0.026\n",
       "Prop. mediated (treated)  0.993276        0.559691        1.348486    0.026\n",
       "ACME (average)           -0.023876       -7.728465        7.182894    0.986\n",
       "ADE (average)             0.073257        0.023600        0.127048    0.010\n",
       "Prop. mediated (average)  0.993276        0.559691        1.348486    0.026"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mediation analysis\n",
    "y = triples['length_r1']\n",
    "X_cols = ['sentiment_q','length_q']\n",
    "X = sm.add_constant(triples[X_cols])\n",
    "mediator_model = sm.OLS(y,X)\n",
    "\n",
    "# For the second step of the mediation model, we can add in other predictors.\n",
    "y = triples['length_r2']\n",
    "X_cols = ['sentiment_q','length_q','fact-feeling_r1','nicenasty_r1','sarcasm_r1','length_r1','sentiment_r1']\n",
    "X = sm.add_constant(triples[X_cols])\n",
    "outcome_model = sm.OLS(y,X)\n",
    "\n",
    "med = Mediation(outcome_model=outcome_model, mediator_model=mediator_model,\n",
    "                exposure='length_q', mediator='length_r1').fit()\n",
    "med.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks the Average Causal Mediated Effect (ACME) is not significantly different from zero, but the Average Direct Effect (ADE). That suggests the true causal relationship here is more of length_q -> length_r2 rather than length_q -> length_r1 -> length_r2. What do you think explains that relationship?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">*Exercise 3*</font>\n",
    "\n",
    "<font color=\"red\">Propose a mediation model related to the simple causal model you proposed above (ideally on the dataset you're using for your final project). If you have measures for each variable in the model, run the analysis: You can just copy the \"Mediation analysis\" cell above and replace with your variables. If you do not have measures, you do not have to run the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text as confounder\n",
    "The causal effect we're interested in estimating might not be our causal relationship of interest. Instead, it could be another variable that affects both our treatment and outcome, known as a _confounder_. Recall the [Keith et al. 2020](https://aclanthology.org/2020.acl-main.474.pdf) figure showing the role of a confounder.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/UChicago-Computational-Content-Analysis/Homework-Notebooks/main/week-6/img/causal_diagram.png\" alt=\"https://raw.githubusercontent.com/UChicago-Computational-Content-Analysis/Homework-Notebooks/main/week-6/img/causal_diagram.png\" style=\"width:500px\">\n",
    "\n",
    "Why do we need to control for confounders? If we didn't, we might correctly find that the treatment and outcome are correlated, but rather than one causing the other, they could both be caused by a third variable. For example, if we are studying the effect of the journal a paper is published in on the citations of the paper, we may be worried that the text of the article affects both whether it is published by the journal and whether people cite it.\n",
    "\n",
    "The factors we controlled for in the Internet Arguments Corpus could be seen as confounders, but there are also specific methods to control for text confounders. As an example, we will walk through the method proposed by [Pryzant et al. (2018)](https://nlp.stanford.edu/pubs/pryzant2018lexicon.pdf).\n",
    "\n",
    "Say that we want to know the effect of product descriptions on product popularity. If I'm a shoe seller, how should I describe my shoes to maximize sales? Suppose I have data on sales of other shoes and want to learn from it:\n",
    "\n",
    "| Description   | Brand   | Sales |\n",
    "|---------------|---------|-------|\n",
    "| buy shoes !     | addidas | 15    |\n",
    "| fresh nike shoes !  | nike    | 35    |\n",
    "| nice nike shoes ! | nike    | 17    |\n",
    "\n",
    "It looks like \"nike\" is associated with higher sales! But that doesn't help me very much because I can't just advertise my shoes as Nikes. That would be incorrect. What if we could build a lexicon of words like \"nike\" associated with certain brands and control for that in my analysis? We could then identify brand-agnostic words like \"fresh\" that have the causal effect of interst. That's Pryzant et al.'s approach!\n",
    "\n",
    "Instead of shoes, we're going to work with Consumer Financial Protection Bureau (CFPB) complaints. When US residents complain about financial products (e..g, mortgages, credit reports), the CFPB sometimes handles these on a \"timely basis (<15 days)\" and sometimes not. If you want to submit a complaint, how should you word it so you get a timely response? We want to control for the differences in wording that result from different products to identify the causal effect of interest. For example, if saying \"mortgage\" is associated with a timely response, that doesn't mean you should throw \"mortgage\" into your complaint about a credit report.\n",
    "\n",
    "Let's download the data and construct a Pandas DataFrame!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded file: https://files.consumerfinance.gov/ccdb/complaints.csv.zip\n"
     ]
    }
   ],
   "source": [
    "url = 'https://files.consumerfinance.gov/ccdb/complaints.csv.zip'\n",
    "\n",
    "req = requests.get(url)\n",
    "\n",
    "filename = url.split('/')[-1]\n",
    "with open(filename,'wb') as output_file:\n",
    "    output_file.write(req.content)\n",
    "print('Downloaded file: ' + url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipfile.ZipFile('complaints.csv.zip').extractall('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3444: DtypeWarning: Columns (10) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Date received</th>\n",
       "      <th>Product</th>\n",
       "      <th>Sub-product</th>\n",
       "      <th>Issue</th>\n",
       "      <th>Sub-issue</th>\n",
       "      <th>Consumer complaint narrative</th>\n",
       "      <th>Company public response</th>\n",
       "      <th>Company</th>\n",
       "      <th>State</th>\n",
       "      <th>ZIP code</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Consumer consent provided?</th>\n",
       "      <th>Submitted via</th>\n",
       "      <th>Date sent to company</th>\n",
       "      <th>Company response to consumer</th>\n",
       "      <th>Timely response?</th>\n",
       "      <th>Consumer disputed?</th>\n",
       "      <th>Complaint ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>2021-06-04</td>\n",
       "      <td>Money transfer, virtual currency, or money ser...</td>\n",
       "      <td>Virtual currency</td>\n",
       "      <td>Other service problem</td>\n",
       "      <td>NaN</td>\n",
       "      <td>On XX/XX/XXXX Coinbase disabled my account due...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Coinbase, Inc.</td>\n",
       "      <td>NC</td>\n",
       "      <td>28027.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Consent provided</td>\n",
       "      <td>Web</td>\n",
       "      <td>2021-06-04</td>\n",
       "      <td>Closed with monetary relief</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4430771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>2021-09-06</td>\n",
       "      <td>Mortgage</td>\n",
       "      <td>VA mortgage</td>\n",
       "      <td>Struggling to pay mortgage</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I applied for and was granted forbearance at t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FIFTH THIRD FINANCIAL CORPORATION</td>\n",
       "      <td>OH</td>\n",
       "      <td>45414.0</td>\n",
       "      <td>Servicemember</td>\n",
       "      <td>Consent provided</td>\n",
       "      <td>Web</td>\n",
       "      <td>2021-09-06</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4697086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23</td>\n",
       "      <td>2021-11-20</td>\n",
       "      <td>Credit card or prepaid card</td>\n",
       "      <td>General-purpose credit card or charge card</td>\n",
       "      <td>Other features, terms, or problems</td>\n",
       "      <td>Other problem</td>\n",
       "      <td>I opened a PayPal account so that my unemploym...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Paypal Holdings, Inc</td>\n",
       "      <td>TX</td>\n",
       "      <td>76119.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Consent provided</td>\n",
       "      <td>Web</td>\n",
       "      <td>2021-11-20</td>\n",
       "      <td>Closed with non-monetary relief</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4930990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24</td>\n",
       "      <td>2017-04-29</td>\n",
       "      <td>Debt collection</td>\n",
       "      <td>Credit card debt</td>\n",
       "      <td>Threatened to contact someone or share informa...</td>\n",
       "      <td>Contacted you after you asked them to stop</td>\n",
       "      <td>I have judgment hurting my ability to get a jo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hunt &amp; Henriques</td>\n",
       "      <td>CA</td>\n",
       "      <td>91711.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Consent provided</td>\n",
       "      <td>Web</td>\n",
       "      <td>2017-05-30</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2470819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>2020-07-06</td>\n",
       "      <td>Student loan</td>\n",
       "      <td>Private student loan</td>\n",
       "      <td>Struggling to repay your loan</td>\n",
       "      <td>Can't temporarily delay making payments</td>\n",
       "      <td>I notified Sallie Mae in XX/XX/2019 that I was...</td>\n",
       "      <td>Company believes it acted appropriately as aut...</td>\n",
       "      <td>SLM CORPORATION</td>\n",
       "      <td>KY</td>\n",
       "      <td>40422.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Consent provided</td>\n",
       "      <td>Web</td>\n",
       "      <td>2020-07-22</td>\n",
       "      <td>Closed with non-monetary relief</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3731581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861401</th>\n",
       "      <td>2467079</td>\n",
       "      <td>2015-07-14</td>\n",
       "      <td>Credit card</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Delinquent account</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Automated calls from \" XXXX with Capital One '...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CAPITAL ONE FINANCIAL CORPORATION</td>\n",
       "      <td>TX</td>\n",
       "      <td>77584.0</td>\n",
       "      <td>Servicemember</td>\n",
       "      <td>Consent provided</td>\n",
       "      <td>Web</td>\n",
       "      <td>2015-07-14</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>1466882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861402</th>\n",
       "      <td>2467080</td>\n",
       "      <td>2017-02-09</td>\n",
       "      <td>Debt collection</td>\n",
       "      <td>I do not know</td>\n",
       "      <td>Cont'd attempts collect debt not owed</td>\n",
       "      <td>Debt resulted from identity theft</td>\n",
       "      <td>I have disputed my debts several times with no...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bonneville Billing and Collections</td>\n",
       "      <td>UT</td>\n",
       "      <td>84054.0</td>\n",
       "      <td>Servicemember</td>\n",
       "      <td>Consent provided</td>\n",
       "      <td>Web</td>\n",
       "      <td>2017-02-09</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>2334969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861403</th>\n",
       "      <td>2467081</td>\n",
       "      <td>2015-04-29</td>\n",
       "      <td>Mortgage</td>\n",
       "      <td>Conventional fixed mortgage</td>\n",
       "      <td>Loan modification,collection,foreclosure</td>\n",
       "      <td>NaN</td>\n",
       "      <td>My father died in XX/XX/XXXX. Left me his only...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CITIBANK, N.A.</td>\n",
       "      <td>OK</td>\n",
       "      <td>74066.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Consent provided</td>\n",
       "      <td>Web</td>\n",
       "      <td>2015-04-29</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>1352738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861404</th>\n",
       "      <td>2467082</td>\n",
       "      <td>2017-03-31</td>\n",
       "      <td>Credit reporting</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Credit reporting company's investigation</td>\n",
       "      <td>No notice of investigation status/result</td>\n",
       "      <td>cfbp i would Like to file a complaint on Exper...</td>\n",
       "      <td>Company has responded to the consumer and the ...</td>\n",
       "      <td>Experian Information Solutions Inc.</td>\n",
       "      <td>MN</td>\n",
       "      <td>55379.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Consent provided</td>\n",
       "      <td>Web</td>\n",
       "      <td>2017-03-31</td>\n",
       "      <td>Closed with non-monetary relief</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2412926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861405</th>\n",
       "      <td>2467083</td>\n",
       "      <td>2017-01-16</td>\n",
       "      <td>Credit reporting</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Incorrect information on credit report</td>\n",
       "      <td>Account status</td>\n",
       "      <td>My husband and I are in the middle of an FHA S...</td>\n",
       "      <td>Company has responded to the consumer and the ...</td>\n",
       "      <td>TRANSUNION INTERMEDIATE HOLDINGS, INC.</td>\n",
       "      <td>GA</td>\n",
       "      <td>30215.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Consent provided</td>\n",
       "      <td>Web</td>\n",
       "      <td>2017-01-16</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>2292586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>861406 rows Ã— 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id Date received  \\\n",
       "0             4    2021-06-04   \n",
       "1             5    2021-09-06   \n",
       "2            23    2021-11-20   \n",
       "3            24    2017-04-29   \n",
       "4            32    2020-07-06   \n",
       "...         ...           ...   \n",
       "861401  2467079    2015-07-14   \n",
       "861402  2467080    2017-02-09   \n",
       "861403  2467081    2015-04-29   \n",
       "861404  2467082    2017-03-31   \n",
       "861405  2467083    2017-01-16   \n",
       "\n",
       "                                                  Product  \\\n",
       "0       Money transfer, virtual currency, or money ser...   \n",
       "1                                                Mortgage   \n",
       "2                             Credit card or prepaid card   \n",
       "3                                         Debt collection   \n",
       "4                                            Student loan   \n",
       "...                                                   ...   \n",
       "861401                                        Credit card   \n",
       "861402                                    Debt collection   \n",
       "861403                                           Mortgage   \n",
       "861404                                   Credit reporting   \n",
       "861405                                   Credit reporting   \n",
       "\n",
       "                                       Sub-product  \\\n",
       "0                                 Virtual currency   \n",
       "1                                      VA mortgage   \n",
       "2       General-purpose credit card or charge card   \n",
       "3                                 Credit card debt   \n",
       "4                             Private student loan   \n",
       "...                                            ...   \n",
       "861401                                         NaN   \n",
       "861402                               I do not know   \n",
       "861403                 Conventional fixed mortgage   \n",
       "861404                                         NaN   \n",
       "861405                                         NaN   \n",
       "\n",
       "                                                    Issue  \\\n",
       "0                                   Other service problem   \n",
       "1                              Struggling to pay mortgage   \n",
       "2                      Other features, terms, or problems   \n",
       "3       Threatened to contact someone or share informa...   \n",
       "4                           Struggling to repay your loan   \n",
       "...                                                   ...   \n",
       "861401                                 Delinquent account   \n",
       "861402              Cont'd attempts collect debt not owed   \n",
       "861403           Loan modification,collection,foreclosure   \n",
       "861404           Credit reporting company's investigation   \n",
       "861405             Incorrect information on credit report   \n",
       "\n",
       "                                         Sub-issue  \\\n",
       "0                                              NaN   \n",
       "1                                              NaN   \n",
       "2                                    Other problem   \n",
       "3       Contacted you after you asked them to stop   \n",
       "4          Can't temporarily delay making payments   \n",
       "...                                            ...   \n",
       "861401                                         NaN   \n",
       "861402           Debt resulted from identity theft   \n",
       "861403                                         NaN   \n",
       "861404    No notice of investigation status/result   \n",
       "861405                              Account status   \n",
       "\n",
       "                             Consumer complaint narrative  \\\n",
       "0       On XX/XX/XXXX Coinbase disabled my account due...   \n",
       "1       I applied for and was granted forbearance at t...   \n",
       "2       I opened a PayPal account so that my unemploym...   \n",
       "3       I have judgment hurting my ability to get a jo...   \n",
       "4       I notified Sallie Mae in XX/XX/2019 that I was...   \n",
       "...                                                   ...   \n",
       "861401  Automated calls from \" XXXX with Capital One '...   \n",
       "861402  I have disputed my debts several times with no...   \n",
       "861403  My father died in XX/XX/XXXX. Left me his only...   \n",
       "861404  cfbp i would Like to file a complaint on Exper...   \n",
       "861405  My husband and I are in the middle of an FHA S...   \n",
       "\n",
       "                                  Company public response  \\\n",
       "0                                                     NaN   \n",
       "1                                                     NaN   \n",
       "2                                                     NaN   \n",
       "3                                                     NaN   \n",
       "4       Company believes it acted appropriately as aut...   \n",
       "...                                                   ...   \n",
       "861401                                                NaN   \n",
       "861402                                                NaN   \n",
       "861403                                                NaN   \n",
       "861404  Company has responded to the consumer and the ...   \n",
       "861405  Company has responded to the consumer and the ...   \n",
       "\n",
       "                                       Company State ZIP code           Tags  \\\n",
       "0                               Coinbase, Inc.    NC  28027.0            NaN   \n",
       "1            FIFTH THIRD FINANCIAL CORPORATION    OH  45414.0  Servicemember   \n",
       "2                         Paypal Holdings, Inc    TX  76119.0            NaN   \n",
       "3                             Hunt & Henriques    CA  91711.0            NaN   \n",
       "4                              SLM CORPORATION    KY  40422.0            NaN   \n",
       "...                                        ...   ...      ...            ...   \n",
       "861401       CAPITAL ONE FINANCIAL CORPORATION    TX  77584.0  Servicemember   \n",
       "861402      Bonneville Billing and Collections    UT  84054.0  Servicemember   \n",
       "861403                          CITIBANK, N.A.    OK  74066.0            NaN   \n",
       "861404     Experian Information Solutions Inc.    MN  55379.0            NaN   \n",
       "861405  TRANSUNION INTERMEDIATE HOLDINGS, INC.    GA  30215.0            NaN   \n",
       "\n",
       "       Consumer consent provided? Submitted via Date sent to company  \\\n",
       "0                Consent provided           Web           2021-06-04   \n",
       "1                Consent provided           Web           2021-09-06   \n",
       "2                Consent provided           Web           2021-11-20   \n",
       "3                Consent provided           Web           2017-05-30   \n",
       "4                Consent provided           Web           2020-07-22   \n",
       "...                           ...           ...                  ...   \n",
       "861401           Consent provided           Web           2015-07-14   \n",
       "861402           Consent provided           Web           2017-02-09   \n",
       "861403           Consent provided           Web           2015-04-29   \n",
       "861404           Consent provided           Web           2017-03-31   \n",
       "861405           Consent provided           Web           2017-01-16   \n",
       "\n",
       "           Company response to consumer Timely response? Consumer disputed?  \\\n",
       "0           Closed with monetary relief              Yes                NaN   \n",
       "1               Closed with explanation              Yes                NaN   \n",
       "2       Closed with non-monetary relief              Yes                NaN   \n",
       "3               Closed with explanation              Yes                NaN   \n",
       "4       Closed with non-monetary relief              Yes                NaN   \n",
       "...                                 ...              ...                ...   \n",
       "861401          Closed with explanation              Yes                 No   \n",
       "861402          Closed with explanation              Yes                 No   \n",
       "861403          Closed with explanation              Yes                 No   \n",
       "861404  Closed with non-monetary relief              Yes                Yes   \n",
       "861405          Closed with explanation              Yes                 No   \n",
       "\n",
       "        Complaint ID  \n",
       "0            4430771  \n",
       "1            4697086  \n",
       "2            4930990  \n",
       "3            2470819  \n",
       "4            3731581  \n",
       "...              ...  \n",
       "861401       1466882  \n",
       "861402       2334969  \n",
       "861403       1352738  \n",
       "861404       2412926  \n",
       "861405       2292586  \n",
       "\n",
       "[861406 rows x 19 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complaints = pd.read_csv('complaints.csv')\n",
    "complaints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very interesting! So our goal is to build a lexicon associated with the `Product` column in order to better identify the effect of wording choices in `Consumer complaint narrative` on whether `Timely response?` is `Yes` or `No`. Fortunately Pryzant et al. made a very convenient package to build such a lexicon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting causal-attribution\n",
      "  Downloading causal_attribution-1.1-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: scipy in c:\\programdata\\anaconda3\\lib\\site-packages (from causal-attribution) (1.7.1)\n",
      "Requirement already satisfied: nltk in c:\\programdata\\anaconda3\\lib\\site-packages (from causal-attribution) (3.6.5)\n",
      "Collecting sklearn\n",
      "  Using cached sklearn-0.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: pandas in c:\\programdata\\anaconda3\\lib\\site-packages (from causal-attribution) (1.3.4)\n",
      "Requirement already satisfied: torch>=1.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from causal-attribution) (1.7.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\jacy\\appdata\\roaming\\python\\python38\\site-packages (from torch>=1.0.0->causal-attribution) (3.7.4.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\jacy\\appdata\\roaming\\python\\python38\\site-packages (from torch>=1.0.0->causal-attribution) (1.19.5)\n",
      "Requirement already satisfied: click in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk->causal-attribution) (8.0.3)\n",
      "Requirement already satisfied: joblib in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk->causal-attribution) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk->causal-attribution) (2021.8.3)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk->causal-attribution) (4.62.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\jacy\\appdata\\roaming\\python\\python38\\site-packages (from click->nltk->causal-attribution) (0.4.4)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas->causal-attribution) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\jacy\\appdata\\roaming\\python\\python38\\site-packages (from pandas->causal-attribution) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\jacy\\appdata\\roaming\\python\\python38\\site-packages (from python-dateutil>=2.7.3->pandas->causal-attribution) (1.15.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\programdata\\anaconda3\\lib\\site-packages (from sklearn->causal-attribution) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn->causal-attribution) (2.2.0)\n",
      "Installing collected packages: sklearn, causal-attribution\n",
      "Successfully installed causal-attribution-1.1 sklearn-0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -nsim (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -lrd (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensim (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -nsim (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -lrd (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensim (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -nsim (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -lrd (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensim (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -nsim (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -lrd (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensim (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -nsim (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -lrd (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensim (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -nsim (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -lrd (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensim (c:\\programdata\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install causal-attribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import causal_attribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use their function called `causal_attribution.score_vocab()`. This takes as input a vocabulary of words that we want to assess, the CSV file with data, and a dictionary that tells the function which column of the CSV is your input, your control, and your intended prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jacy\\AppData\\Local\\Temp/ipykernel_15908/783068988.py:1: DtypeWarning: Columns (9) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  importance_scores = causal_attribution.score_vocab(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "defaultdict(<function causal_attribution.models.VocabScoringModel.interpret.<locals>.<lambda>()>,\n",
       "            {'Timely response?': defaultdict(list,\n",
       "                         {'UNK': [('bad', -0.4140066469553858),\n",
       "                           ('PAD', -0.486936925444752),\n",
       "                           ('loan', -0.6336907864897512),\n",
       "                           ('UNK', -6.607560748234391),\n",
       "                           ('mortgage', -6.6500365333631635)],\n",
       "                          'No': [('loan', 0.6001077571272617),\n",
       "                           ('bad', 0.40088386880233884),\n",
       "                           ('UNK', -0.06899466807954013),\n",
       "                           ('PAD', -0.2665790911996737),\n",
       "                           ('mortgage', -1.0340577753959224)],\n",
       "                          'Yes': [('mortgage', 3.6836068082920974),\n",
       "                           ('UNK', 3.059266816242598),\n",
       "                           ('PAD', 0.2291519903083099),\n",
       "                           ('loan', 0.15485225079464726),\n",
       "                           ('bad', -0.1762437695870176)]})})"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance_scores = causal_attribution.score_vocab(\n",
    "    vocab=['mortgage','bad','loan'],\n",
    "    csv='complaints.csv',\n",
    "    delimiter=\",\",\n",
    "    name_to_type={\n",
    "        'Consumer complaint narrative': 'input',\n",
    "        'Product': 'control',\n",
    "        'Timely response?': 'predict',\n",
    "    })\n",
    "\n",
    "importance_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customization of text to fit causal inference methods\n",
    "\n",
    "2020 Causal Embedding Veitch and Blei\n",
    "https://github.com/blei-lab/causal-text-embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start with data from the paper"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
